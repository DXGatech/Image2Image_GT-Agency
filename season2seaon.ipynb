{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "season2seaon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlSVbFlgfEBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch # might switch to keras; for now keep PyTorch\n",
        "import torchvision\n",
        "import glob\n",
        "from numpy import asarray # image to float32 tensors\n",
        "from numpy import vstack # integrating dataset folders\n",
        "from numpy import savez_compressed # compress preprocessed image data to numpy format file\n",
        "from os import listdir\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Sampler\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.optim import Adam\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3gp2Y_wgAEh",
        "colab_type": "code",
        "outputId": "bc63ec97-f872-42a5-98b0-f0630fc63bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_size = (256, 256)\n",
        "# This is potentially problematic because we are not separating the sets\n",
        "DATAPATH_TRAIN = \"/\"\n",
        "DATAPATH_TEST = \"/\"\n",
        "images = glob.glob(DATAPATH_TRAIN + \"/*.jpg\") # probably png\n",
        "\n",
        "def visualize_untransformed(image): # visualize the untransformed images. Will NOT be used for training\n",
        "  img = Image.open(image)\n",
        "  to_PIL = transforms.ToPILImage()\n",
        "  to_Tensor = transforms.ToTensor()\n",
        "  data_img = to_Tensor(img)\n",
        "  display_img = to_PIL(to_Tensor(img).convert(\"RGB\")) # this is very likely problematic\n",
        "  plt.imshow(display_img)\n",
        "\n",
        "def visualize_transformed(image_tensor): # visualize transformed individual un-batched images. Will NOT be used for training\n",
        "  transformed = transforms.ToPILImage()(image_tensor).convert(\"RGB\")\n",
        "  plt.imshow(transformed)\n",
        "\n",
        "def transform_original(image_dataset):\n",
        "  transform_image = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.CenterCrop((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "  ])\n",
        "\n",
        "  transform_normalize = transforms.Normalize([\n",
        "    mean = [0.5, 0.5, 0.5],\n",
        "    std = [0.5, 0.5, 0.5] # placeholder values. Change after consulting with official implementation\n",
        "  ])\n",
        "\n",
        "  # TODO: stack X and Y images since they are in different folders\n",
        "  train_data = torchvision.datasets.ImageFolder(DATAPATH_TRAIN, transform = transform_image)\n",
        "  train_dl = torch.utils.data.DataLoader(train_data, batch_size = 1, shuffle = True, num_workers = 5)\n",
        "\n",
        "  test_data = torchvision.datasets.ImageFolder(DATAPATH_TEST, transform = transform.image)\n",
        "  test_dl = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle = True, num_workers = 5)\n",
        "\n",
        "def train(dataloader):\n",
        "  for img in dataloader: # we don't need a label\n",
        "    #model training starts here\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "'''transform = transforms.Compose([\n",
        "\n",
        "])'''\n",
        "'''def load_images(path):\n",
        "  for filename in listdir(path):'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def load_images(path):\\n  for filename in listdir(path):'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBc3I_h0gScu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}